{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extended MNIST\n",
    "\n",
    "L'obiettivo del progetto è il riconoscimento e la conseguente classificazione di immagini rappresentati lettere scritte a mano. Il dataset fornito è composto da 80000 immagini di stessa dimensione (28x28), rappresentate in scala di grigi. Non viene fatta distizione tra lettere maiuscole e minuscole, quindi le classi da individuare sono 26."
   ],
   "id": "2830136a6573fb48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Approccio alla soluzione\n",
    "\n",
    "Verranno utilizzati più modelli per la soluzione al problema, partendo da un modello di base (Logistic Regression) fino ad arrivare a modelli più complessi (Neural Network). Le prestazioni di ogni modello verrano giudicate in base all'accuratezza ed al tempo di esecuzione.  "
   ],
   "id": "a97ed62833dd2b0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T20:25:16.867326Z",
     "start_time": "2024-06-12T20:25:16.743910Z"
    }
   },
   "source": [
    "#import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#utility functions\n",
    "\n",
    "#time monitor\n",
    "def elapsed_time(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Time spent training: {:0>2}:{:0>2}:{:0>2}\".format(int(hours),int(minutes),int(seconds)))\n",
    "\n",
    "#accuracy printer\n",
    "def print_accuracy_scores(train_labels, test_labels, predictions_train_model, predictions_test_model):\n",
    "    acc_train = accuracy_score(train_labels, predictions_train_model)\n",
    "    acc_test = accuracy_score(test_labels, predictions_test_model)\n",
    "    print('Training set accuracy:   {:.3f}'.format(acc_train))\n",
    "    print('Test set accuracy:       {:.3f}'.format(acc_test))\n",
    "\n",
    "#confusion matrix printer\n",
    "def plot_confusion_matrix(train_labels, predictions_train):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(train_labels, predictions_train, normalize='true', cmap='Blues')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.grid(None)\n",
    "    plt.show()"
   ],
   "id": "d0efd228fa99c2f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I dati sono stati divisi in 3 set: train (70%), validation (15%) e test set(15%).",
   "id": "c4b195c8a88d75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T20:25:30.213544Z",
     "start_time": "2024-06-12T20:25:19.993868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#reading data from csv and split the data in train, validation and test sets\n",
    "\n",
    "df = pd.read_csv(\"emnist-letters.csv\")\n",
    "X = df.iloc[:,1:].to_numpy().reshape(-1, 28, 28, order=\"F\")\n",
    "y = df.iloc[:,0].to_numpy()-1\n",
    "print(y)\n",
    "\n",
    "train_images, test_val_images, train_labels, test_val_labels = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(test_val_images, test_val_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "X = np.concatenate((train_images, val_images), axis=0)\n",
    "y = np.concatenate((train_labels, val_labels), axis=0)\n",
    "split_index = [-1]*len(train_images) + [0]*len(val_images)\n",
    "pds = PredefinedSplit(test_fold = split_index)\n"
   ],
   "id": "e301b3c8b7bbd37f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 15 14 ...  0 22 11]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Softmax Regression\n",
    "\n",
    "Prima di applicare ogni modello, attraverso una GridSearch si individua la migliore combinazione dei parametri del modello scelto. A causa dei tempi di esecuzioni troppo elevati, non è stato possibile usare una cross-validation, ma una semplice \"1fold\"."
   ],
   "id": "29cb557c3a2c9374"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nel caso della Softmax Regression, i paramteri soggetti a tuning sono:\n",
    " - C (il fattore di regolarizzazione)\n",
    "  - max_iter (il numero massimo di iterazioni del solver)."
   ],
   "id": "f8a4dee6d26d5e1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "params = {\"C\":[0.1, 0.01, 0.001],\n",
    "         \"max_iter\":[100, 200, 500, 1000]}\n",
    "clf = GridSearchCV(LogisticRegression(multi_class='multinomial', n_jobs=-1), params, scoring='accuracy', return_train_score=True, cv=pds)\n",
    "\n",
    "time_start = time()\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "time_end = time()\n",
    "elapsed_time(time_start, time_end)"
   ],
   "id": "ccbb09da403b631a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "clf.best_estimator_",
   "id": "c9820af7100c4a2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "clf.best_score_",
   "id": "d00e5b4ffc6fe95d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "log_reg = LogisticRegression(multi_class='multinomial', n_jobs=-1, C=0.01, max_iter=1000)\n",
    "time_start = time()\n",
    "log_reg.fit(train_images, train_labels)\n",
    "time_end = time()\n",
    "elapsed_time(time_start, time_end)\n",
    "\n",
    "predictions_test = log_reg.predict(test_images)\n",
    "predictions_train = log_reg.predict(train_images)\n",
    "\n",
    "print_accuracy_scores(train_labels, test_labels, predictions_train, predictions_test)\n",
    "plot_confusion_matrix(train_labels, predictions_train)"
   ],
   "id": "cc58b7c57fac3bdd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Random forest\n",
    "\n",
    "Nella Random Forest, i paramteri soggetti a tuning sono:\n",
    "- n_estimators (il numero di alberi)\n",
    "- criterion (funzione di impurità)\n",
    "- min_samples_split (il numeri minimo di elementi di un nodo affinché possa essere partizionato)\n",
    "- max_depth (profondità dell'albero).\n",
    "\n",
    "La suddivisione del dataset in train, validatione test set rimane la stessa: 70% train set, 15% test set e 15% validation set.\n"
   ],
   "id": "b05649dd8e193728"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_estimators =[50, 100, 200, 500, 1000] \n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "min_samples_split = [2, 4, 8, 16, 32, 64, 128, 256, 1024, 2048]\n",
    "max_depth = [1, 5, 10, 20, 45, 50]\n",
    "\n",
    "def build_random_forest(hp):\n",
    "    model = RandomForestClassifier(\n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        n_estimators=hp.Choice(\"n_estimators\", n_estimators),\n",
    "        criterion=hp.Choice(\"criterion\", criterion),\n",
    "        min_samples_split=hp.Choice(\"min_samples_split\", min_samples_split),\n",
    "        max_depth=hp.Choice('max_depth', max_depth))\n",
    "    return model"
   ],
   "id": "be1534c3700b389d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rf_trials=80\n",
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.RandomSearchOracle(objective=kt.Objective('score', 'max'),max_trials=rf_trials, seed=42),\n",
    "    scoring='accuracy',\n",
    "    hypermodel= build_random_forest,\n",
    "    cv=pds,\n",
    "    project_name='tuners/random_forest')\n",
    "\n",
    "tuner.search(X, y)\n",
    "#gc.collect()\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\nBest criterion:        \", best_hps.get(\"criterion\"))\n",
    "print(\"Best max_depth:          \", best_hps.get(\"max_depth\"))\n",
    "print(\"Best n_estimators:       \", best_hps.get(\"n_estimators\"))\n",
    "print(\"Best min_samples_split:  \", best_hps.get(\"min_samples_split\"))"
   ],
   "id": "88aef0e9efbceeb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, criterion=best_hps.get(\"criterion\"), \n",
    "                               max_depth=best_hps.get(\"max_depth\"), n_estimators=best_hps.get(\"n_estimators\"), min_samples_split=best_hps.get(\"min_samples_split\"))\n",
    "time_start = time()\n",
    "model.fit(train_images, train_labels)\n",
    "time_end = time()\n",
    "elapsed_time(time_start, time_end) \n",
    "print(\"\")\n",
    "\n",
    "predictions_test = model.predict(test_images)\n",
    "predictions_train = model.predict(train_images)\n",
    "\n",
    "print_accuracy_scores(train_labels, test_labels, predictions_train, predictions_test)\n",
    "plot_confusion_matrix(train_labels, predictions_train)"
   ],
   "id": "8ddcd14612ed897b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Reti neurali convoluzionali (CNN)\n",
    "\n",
    "Come ultimo modello si è scelto di utilizzare una CNN. Partendo da una rete semplice, questa verrà resa più complessa con l'aggiunta di nuovi layer ed ad ogni modello verrà applicato il tuning degli iperparametri."
   ],
   "id": "83dd28cf7a31edd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Modello 0\n",
   "id": "30ab05956697e16a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
