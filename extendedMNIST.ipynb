{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Extended MNIST\n",
    "\n",
    "L'obiettivo del progetto è il riconoscimento e la conseguente classificazione di immagini rappresentati lettere scritte a mano. Il dataset fornito è composto da 80000 immagini di stessa dimensione (28x28), rappresentate in scala di grigi. Non viene fatta distizione tra lettere maiuscole e minuscole, quindi le classi da individuare sono 26."
   ],
   "id": "2830136a6573fb48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Approccio alla soluzione\n",
    "\n",
    "Verranno utilizzati più modelli per la soluzione al problema, partendo da un modello di base (Logistic Regression) fino ad arrivare a modelli più complessi (Neural Network). Le prestazioni di ogni modello verrano giudicate in base all'accuratezza ed al tempo di esecuzione.  "
   ],
   "id": "a97ed62833dd2b0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-04T13:00:13.859092Z",
     "start_time": "2024-09-04T12:59:55.693109Z"
    }
   },
   "source": [
    "#import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#utility functions\n",
    "\n",
    "#time monitor\n",
    "def elapsed_time(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Time spent training: {:0>2}:{:0>2}:{:0>2}\".format(int(hours),int(minutes),int(seconds)))\n",
    "\n",
    "#accuracy printer\n",
    "def print_accuracy_scores(train_labels, test_labels, predictions_train_model, predictions_test_model):\n",
    "    acc_train = accuracy_score(train_labels, predictions_train_model)\n",
    "    acc_test = accuracy_score(test_labels, predictions_test_model)\n",
    "    print('Training set accuracy:   {:.3f}'.format(acc_train))\n",
    "    print('Test set accuracy:       {:.3f}'.format(acc_test))\n",
    "\n",
    "def plot_measure(history_train, history_test, title='', xticks=None):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(history_train, marker='o', markersize=5, label='Train')\n",
    "    plt.plot(history_test, marker='o', markersize=5, label='Validation')\n",
    "    plt.legend()\n",
    "    if xticks is None:\n",
    "        plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "    else:\n",
    "        #plt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "        ax = plt.subplot(111)\n",
    "        ax.set_xlim(xticks[0], xticks[-1])\n",
    "        plt.xticks(xticks)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "#accuracy printer\n",
    "def plot_accuracy(history_df):\n",
    "    plot_measure(history_df.accuracy, history_df.val_accuracy, 'Accuracy')\n",
    "    \n",
    "#loss printer\n",
    "def plot_loss(history_df):\n",
    "    plot_measure(history_df.loss, history_df.val_loss, 'Loss')\n",
    "\n",
    "#confusion matrix printer\n",
    "def plot_confusion_matrix(train_labels, predictions_train):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(train_labels, predictions_train, normalize='true', cmap='Blues')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.grid(None)\n",
    "    plt.show()"
   ],
   "id": "d0efd228fa99c2f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I dati sono stati divisi in 3 set: train (70%), validation (15%) e test set(15%).",
   "id": "c4b195c8a88d75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T20:25:30.213544Z",
     "start_time": "2024-06-12T20:25:19.993868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#reading data from csv and split the data in train, validation and test sets\n",
    "\n",
    "df = pd.read_csv(\"emnist-letters.csv\")\n",
    "X = df.iloc[:,1:].to_numpy().reshape(-1, 28, 28, order=\"F\")\n",
    "y = df.iloc[:,0].to_numpy()-1\n",
    "print(y)\n",
    "\n",
    "train_images, test_val_images, train_labels, test_val_labels = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(test_val_images, test_val_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "X = np.concatenate((train_images, val_images), axis=0)\n",
    "y = np.concatenate((train_labels, val_labels), axis=0)\n",
    "split_index = [-1]*len(train_images) + [0]*len(val_images)\n",
    "pds = PredefinedSplit(test_fold = split_index)\n"
   ],
   "id": "e301b3c8b7bbd37f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 15 14 ...  0 22 11]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Softmax Regression\n",
    "\n",
    "Prima di applicare ogni modello, attraverso una GridSearch si individua la migliore combinazione dei parametri del modello scelto. A causa dei tempi di esecuzioni troppo elevati, non è stato possibile usare una cross-validation, ma una semplice \"1fold\"."
   ],
   "id": "29cb557c3a2c9374"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nel caso della Softmax Regression, i paramteri soggetti a tuning sono:\n",
    " - C (il fattore di regolarizzazione)\n",
    "  - max_iter (il numero massimo di iterazioni del solver)."
   ],
   "id": "f8a4dee6d26d5e1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "params = {\"C\":[0.1, 0.01, 0.001],\n",
    "         \"max_iter\":[100, 200, 500, 1000]}\n",
    "clf = GridSearchCV(LogisticRegression(multi_class='multinomial', n_jobs=-1), params, scoring='accuracy', return_train_score=True, cv=pds)\n",
    "\n",
    "time_start = time()\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "time_end = time()\n",
    "elapsed_time(time_start, time_end)"
   ],
   "id": "ccbb09da403b631a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "clf.best_estimator_",
   "id": "c9820af7100c4a2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "clf.best_score_",
   "id": "d00e5b4ffc6fe95d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "log_reg = LogisticRegression(multi_class='multinomial', n_jobs=-1, C=0.01, max_iter=1000)\n",
    "time_start = time()\n",
    "log_reg.fit(train_images, train_labels)\n",
    "time_end = time()\n",
    "elapsed_time(time_start, time_end)\n",
    "\n",
    "predictions_test = log_reg.predict(test_images)\n",
    "predictions_train = log_reg.predict(train_images)\n",
    "\n",
    "print_accuracy_scores(train_labels, test_labels, predictions_train, predictions_test)\n",
    "plot_confusion_matrix(train_labels, predictions_train)"
   ],
   "id": "cc58b7c57fac3bdd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Random forest\n",
    "\n",
    "Nella Random Forest, i paramteri soggetti a tuning sono:\n",
    "- n_estimators (il numero di alberi)\n",
    "- criterion (funzione di impurità)\n",
    "- min_samples_split (il numeri minimo di elementi di un nodo affinché possa essere partizionato)\n",
    "- max_depth (profondità dell'albero).\n",
    "\n",
    "La suddivisione del dataset in train, validatione test set rimane la stessa: 70% train set, 15% test set e 15% validation set.\n"
   ],
   "id": "b05649dd8e193728"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_estimators =[50, 100, 200, 500, 1000] \n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "min_samples_split = [2, 4, 8, 16, 32, 64, 128, 256, 1024, 2048]\n",
    "max_depth = [1, 5, 10, 20, 45, 50]\n",
    "\n",
    "def build_random_forest(hp):\n",
    "    model = RandomForestClassifier(\n",
    "        n_jobs=-1, \n",
    "        random_state=42,\n",
    "        n_estimators=hp.Choice(\"n_estimators\", n_estimators),\n",
    "        criterion=hp.Choice(\"criterion\", criterion),\n",
    "        min_samples_split=hp.Choice(\"min_samples_split\", min_samples_split),\n",
    "        max_depth=hp.Choice('max_depth', max_depth))\n",
    "    return model"
   ],
   "id": "be1534c3700b389d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rf_trials=80\n",
    "tuner = kt.tuners.SklearnTuner(\n",
    "    oracle=kt.oracles.RandomSearchOracle(objective=kt.Objective('score', 'max'),max_trials=rf_trials, seed=42),\n",
    "    scoring='accuracy',\n",
    "    hypermodel= build_random_forest,\n",
    "    cv=pds,\n",
    "    project_name='tuners/random_forest')\n",
    "\n",
    "tuner.search(X, y)\n",
    "#gc.collect()\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\nBest criterion:        \", best_hps.get(\"criterion\"))\n",
    "print(\"Best max_depth:          \", best_hps.get(\"max_depth\"))\n",
    "print(\"Best n_estimators:       \", best_hps.get(\"n_estimators\"))\n",
    "print(\"Best min_samples_split:  \", best_hps.get(\"min_samples_split\"))"
   ],
   "id": "88aef0e9efbceeb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, criterion=best_hps.get(\"criterion\"), \n",
    "                               max_depth=best_hps.get(\"max_depth\"), n_estimators=best_hps.get(\"n_estimators\"), min_samples_split=best_hps.get(\"min_samples_split\"))\n",
    "time_start = time()\n",
    "model.fit(train_images, train_labels)\n",
    "time_end = time()\n",
    "elapsed_time(time_start, time_end) \n",
    "print(\"\")\n",
    "\n",
    "predictions_test = model.predict(test_images)\n",
    "predictions_train = model.predict(train_images)\n",
    "\n",
    "print_accuracy_scores(train_labels, test_labels, predictions_train, predictions_test)\n",
    "plot_confusion_matrix(train_labels, predictions_train)"
   ],
   "id": "8ddcd14612ed897b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Reti neurali convoluzionali (CNN)\n",
    "\n",
    "Come ultima tipologia di modello si è scelto di utilizzare una CNN. Verranno analizzati 3 modelli di complessità crescente,  ed ad ogni di essi verrà applicato il tuning degli iperparametri."
   ],
   "id": "83dd28cf7a31edd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#hyperparameters\n",
    "dense_units = [32, 64, 128, 256]\n",
    "l2 = [0.01, 0.001, 0.0001]\n",
    "dropouts_rate = [.20, .30, .40, .50, .60, .70, .80]\n",
    "filters = [[16,32,64], [32, 64, 128]]\n",
    "filter = [16, 32, 64, 128, 256]"
   ],
   "id": "6a4db0df0f2224ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Modello 1\n",
    "\n",
    "Questo modello rappresenta la base per i modelli successivi più complessi. Esso non presenta un layer per la convoluzione, quindi non è classificabile come CNN, bensì abbiamo:\n",
    "- un layer per il rescaling delle immagini\n",
    "- un layer per applicare il flatten dei dati\n",
    "- un layer su cui si applica il tuning per il numero di unità con funzione di attivazione relu\n",
    "- un layer di output, che sarà lo stesso per tutti i modelli, con 26 nodi e la softmax come funzione di attivazione"
   ],
   "id": "30ab05956697e16a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def model1_builder(hp): \n",
    "    model1 = tf.keras.Sequential()\n",
    "    model1.add(tf.keras.layers.Rescaling(1./255, input_shape=(28, 28)))\n",
    "    model1.add(tf.keras.layers.Flatten())\n",
    "    model1.add(tf.keras.layers.Dense(hp.Choice(\"dense_units\", dense_units), activation=\"relu\"))\n",
    "    model1.add(tf.keras.layers.Dense(26, activation=\"softmax\"))\n",
    "    \n",
    "    model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model1"
   ],
   "id": "3dbf73ea4bb1eedb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tuner = kt.GridSearch(model1_builder, kt.Objective(\"val_acc\", direction=\"max\"), project_name='tuners/nn1')\n",
    "tuner.search(train_images, train_labels, epochs=20, validation_data=(val_images, val_labels), callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)], batch_size=128, use_multiprocessing=True)\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "#gc.collect()"
   ],
   "id": "4c0419e9eda13dcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(\"Best Dense units: \", best_hps.get(\"dense_units\"))",
   "id": "45fa3628b001bac8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model1 = tuner.hypermodel.build(best_hps)\n",
    "model1.summary()"
   ],
   "id": "8114dbf54a858669"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "time_start = time()\n",
    "#model_file = \"./best_model/model0.ckpt\"\n",
    "#checkpoint = tf.keras.callbacks.ModelCheckpoint(model_file, monitor=\"val_acc\", mode=\"max\", save_weights_only=True, save_best_only=True, verbose=1) -- sarebbe da usare in callbacks quando fitto il modello per salvare il miglior modello trainato fino a quel momento\n",
    "history_model0 = model1.fit(train_images, train_labels, batch_size=128, epochs=20, verbose=1, validation_data=(val_images, val_labels), callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)])\n",
    "time_end = time()\n",
    "elapsed_time(time_start, time_end)\n",
    "#gc.collect()"
   ],
   "id": "26e6aad6a91ea51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history_model1_df = pd.DataFrame(history_model0.history)\n",
    "plot_loss(history_model1_df)\n",
    "plot_accuracy(history_model1_df)"
   ],
   "id": "d347ed4ee7bf50ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions_train_model1 = np.argmax(model1.predict(train_images), axis=-1)\n",
    "predictions_test_model1 = np.argmax(model1.predict(test_images), axis=-1)"
   ],
   "id": "35ba7d1129476621"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_confusion_matrix(train_labels, predictions_train_model1)\n",
    "plot_confusion_matrix(test_labels, predictions_test_model1)"
   ],
   "id": "96b6db589d3172fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_accuracy_scores(train_labels, test_labels, predictions_train_model1, predictions_test_model1)",
   "id": "64a304da1ddfcc74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Modello 2\n",
    "\n",
    "Questo modello rappresenta la prima rete CNN. Rispetto al modello 0 vengono aggiunti:\n",
    "- un layer convoluzionale (viene applicato il tuning sul filtro del layer)\n",
    "- un fattore di regoralizzazione L2 da apliccare ai layer di Dense"
   ],
   "id": "be2814335b7dbe48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def model2_builder(hp): \n",
    "    k = hp.Choice(\"L2\", l2)\n",
    "    model2 = tf.keras.Sequential()\n",
    "    model2.add(tf.keras.layers.Rescaling(1./255, input_shape=(28, 28)))\n",
    "    model2.add(tf.keras.layers.Conv2D(hp.Choice(\"filter\", filter), 3, padding=\"same\", activation=\"relu\"))\n",
    "    model2.add(tf.keras.layers.MaxPooling2D())\n",
    "    model2.add(tf.keras.layers.Flatten())\n",
    "    model2.add(tf.keras.layers.Dense(hp.Choice(\"dense_units\", dense_units), activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(k)))\n",
    "    model2.add(tf.keras.layers.Dense(26, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.L2(k)))\n",
    "    \n",
    "    model2.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model2\n",
    "\n",
    "#gc.collect()"
   ],
   "id": "615aa80c400919fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#tuning\n",
    "tuner = kt.RandomSearch(model2_builder, kt.Objective(\"val_acc\", direction=\"max\"), 10, 42, project_name='tuners/nn2')\n",
    "tuner.search(train_images, train_labels, epochs=20, validation_data=(val_images, val_labels), callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)], batch_size=128, use_multiprocessing=True)\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "#gc.collect()"
   ],
   "id": "9aea441a910fa71f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Best Dense units: \", best_hps.get(\"dense_units\"))\n",
    "print(\"Best L2 value: \", best_hps.get(\"L2\"))\n",
    "print(\"Best Filter: \", best_hps.get(\"filter\"))"
   ],
   "id": "2397556e571f6ce8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model2 = tuner.hypermodel.build(best_hps)\n",
    "model2.summary()"
   ],
   "id": "157bc9cefdb54918"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#model_file = \"./best_model/model2.ckpt\"\n",
    "#checkpoint = tf.keras.callbacks.ModelCheckpoint(model_file, monitor=\"val_acc\", mode=\"max\", save_weights_only=True, save_best_only=True, verbose=1)\n",
    "history_model2 = model2.fit(train_images, train_labels, batch_size=128, epochs=20, verbose=1, validation_data=(val_images, val_labels), callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)])\n",
    "#gc.collect()"
   ],
   "id": "14cca999529fd63e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history_model2_df = pd.DataFrame(history_model2.history)\n",
    "plot_loss(history_model2_df)\n",
    "plot_accuracy(history_model2_df)"
   ],
   "id": "ad4ddbf1a5bc19c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions_train_model2 = np.argmax(model2.predict(train_images), axis=-1)\n",
    "predictions_test_model2 = np.argmax(model2.predict(test_images), axis=-1)\n",
    "#gc.collect()"
   ],
   "id": "6eab00d0e1014a5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_confusion_matrix(train_labels, predictions_train_model2)\n",
    "plot_confusion_matrix(test_labels, predictions_test_model2)"
   ],
   "id": "55b894f320f9eee2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_accuracy_scores(train_labels, test_labels, predictions_train_model2, predictions_test_model2)",
   "id": "f98aeda5773c1819"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Modello 3\n",
    "\n",
    "Per il terzo modello, viene introdotto un ulteriore layer convoluzionale e un layer di Dropout per marginare l'overfitting. Si hanno due set di filtri separati da applicare ai layer convoluzionali, e i valori per essi vengono scelti attraverso il tuning. Anche il rate di dropout è soggetto a tuning."
   ],
   "id": "c205de223b158282"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def model3_builder(hp): \n",
    "    filters_index = hp.Choice(\"filters_index\", [0, 1])\n",
    "    k = hp.Choice(\"L2\", l2)\n",
    "    model3 = tf.keras.Sequential()\n",
    "    model3.add(tf.keras.layers.Rescaling(1./255, input_shape=(28,28)))\n",
    "    model3.add(tf.keras.layers.Conv2D(filters[filters_index][0], 3, padding=\"same\", activation=\"relu\"))\n",
    "    model3.add(tf.keras.layers.MaxPooling2D())\n",
    "    model3.add(tf.keras.layers.Conv2D(filters[filters_index][1], 3, padding=\"same\", activation=\"relu\"))\n",
    "    model3.add(tf.keras.layers.MaxPooling2D())\n",
    "    model3.add(tf.keras.layers.Dropout(hp.Choice(\"dropout_rate\", dropouts_rate)))\n",
    "    model3.add(tf.keras.layers.Flatten())\n",
    "    model3.add(tf.keras.layers.Dense(hp.Choice(\"dense_units\", dense_units), activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(k)))\n",
    "    model3.add(tf.keras.layers.Dense(26, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.L2(k)))\n",
    "    \n",
    "    model3.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model3"
   ],
   "id": "874ee0fe9c76ae45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tuner = kt.RandomSearch(model3_builder, kt.Objective(\"val_acc\", direction=\"max\"), 10, 42, project_name='tuners/nn3')\n",
    "tuner.search(train_images, train_labels, epochs=20, validation_data=(val_images, val_labels), callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)], batch_size=128, use_multiprocessing=True)\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "#gc.collect()"
   ],
   "id": "712f23f877f02d56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Best Filter: \", filters[best_hps.get(\"filters_index\")])\n",
    "print(\"Best Dropout Rate: \", best_hps.get(\"dropout_rate\"))\n",
    "print(\"Best Dense units: \", best_hps.get(\"dense_units\"))\n",
    "print(\"Best L2 value: \",  best_hps.get(\"L2\"))"
   ],
   "id": "d3f727d090619d5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model3 = tuner.hypermodel.build(best_hps)\n",
    "model3.summary()\n",
    "#gc.collect()"
   ],
   "id": "38b4b0c6013c42b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#model_file = \"./best_model/model3.ckpt\"\n",
    "#checkpoint = tf.keras.callbacks.ModelCheckpoint(model_file, monitor=\"val_acc\", mode=\"max\", save_weights_only=True, save_best_only=True, verbose=1)\n",
    "history_model3 = model3.fit(train_images, train_labels, batch_size=128, epochs=20, verbose=1, validation_data=(val_images, val_labels), callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)])\n",
    "#gc.collect()"
   ],
   "id": "4be8c3dcc9450517"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history_model3_df = pd.DataFrame(history_model3.history)\n",
    "plot_loss(history_model3_df)\n",
    "plot_accuracy(history_model3_df)"
   ],
   "id": "cb5548cd00e89bf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "predictions_train_model3 = np.argmax(model3.predict(train_images), axis=-1)\n",
    "predictions_test_model3 = np.argmax(model3.predict(test_images), axis=-1)\n",
    "#gc.collect()"
   ],
   "id": "ec2b84fa8808bfa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_confusion_matrix(train_labels, predictions_train_model3)\n",
    "plot_confusion_matrix(test_labels, predictions_test_model3)"
   ],
   "id": "f82a23ca2c005e85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print_accuracy_scores(train_labels, test_labels, predictions_train_model3, predictions_test_model3)",
   "id": "193b73b159408b94"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
